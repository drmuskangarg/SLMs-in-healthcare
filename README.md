# SLMs in Healthcare: A Survey
Unlike vanilla contextual pre-trained fundamentally _small_ language models (e.g., ClinicalBERT), our interest lies in compressed and optimized approaches for language models in healthcare, developed as a resource-efficient and domain-specialized solution to LLMs.

## Datasets for Healthcare Informatics
1. MIMIC-III, a freely accessible critical care database. [Paper](https://www.nature.com/articles/sdata201635) | [Link](https://github.com/MIT-LCP/mimic-iii-paper/)

## Existing SLMs for Healthcare
### 100M to 5B parameters
1. BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text. [Paper](https://arxiv.org/pdf/2403.18421) | [Model](https://huggingface.co/stanford-crfm/BioMedLM)

### >5B parameters
1. Me-llama: Foundation large language models for medical applications. [Paper](https://arxiv.org/abs/2402.12749)


## Trained and Optimized SLMs for healthcare

## Compressed LLMs into SLMs for healthcare


